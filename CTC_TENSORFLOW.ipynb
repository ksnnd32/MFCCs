{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksnnd32/MFCCs/blob/master/CTC_TENSORFLOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rJPoU7Ym8eVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0f772884-fba6-4827-f67d-c90265fd0a47"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/igormq/ctc_tensorflow_example.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ctc_tensorflow_example'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "Unpacking objects:   1% (1/60)   \rUnpacking objects:   3% (2/60)   \rUnpacking objects:   5% (3/60)   \rUnpacking objects:   6% (4/60)   \rUnpacking objects:   8% (5/60)   \rUnpacking objects:  10% (6/60)   \rUnpacking objects:  11% (7/60)   \rUnpacking objects:  13% (8/60)   \rUnpacking objects:  15% (9/60)   \rUnpacking objects:  16% (10/60)   \rUnpacking objects:  18% (11/60)   \rUnpacking objects:  20% (12/60)   \rUnpacking objects:  21% (13/60)   \rUnpacking objects:  23% (14/60)   \rUnpacking objects:  25% (15/60)   \rUnpacking objects:  26% (16/60)   \rUnpacking objects:  28% (17/60)   \rUnpacking objects:  30% (18/60)   \rUnpacking objects:  31% (19/60)   \rUnpacking objects:  33% (20/60)   \rUnpacking objects:  35% (21/60)   \rUnpacking objects:  36% (22/60)   \rUnpacking objects:  38% (23/60)   \rUnpacking objects:  40% (24/60)   \rremote: Total 60 (delta 0), reused 0 (delta 0), pack-reused 60\u001b[K\n",
            "Unpacking objects:  41% (25/60)   \rUnpacking objects:  43% (26/60)   \rUnpacking objects:  45% (27/60)   \rUnpacking objects:  46% (28/60)   \rUnpacking objects:  48% (29/60)   \rUnpacking objects:  50% (30/60)   \rUnpacking objects:  51% (31/60)   \rUnpacking objects:  53% (32/60)   \rUnpacking objects:  55% (33/60)   \rUnpacking objects:  56% (34/60)   \rUnpacking objects:  58% (35/60)   \rUnpacking objects:  60% (36/60)   \rUnpacking objects:  61% (37/60)   \rUnpacking objects:  63% (38/60)   \rUnpacking objects:  65% (39/60)   \rUnpacking objects:  66% (40/60)   \rUnpacking objects:  68% (41/60)   \rUnpacking objects:  70% (42/60)   \rUnpacking objects:  71% (43/60)   \rUnpacking objects:  73% (44/60)   \rUnpacking objects:  75% (45/60)   \rUnpacking objects:  76% (46/60)   \rUnpacking objects:  78% (47/60)   \rUnpacking objects:  80% (48/60)   \rUnpacking objects:  81% (49/60)   \rUnpacking objects:  83% (50/60)   \rUnpacking objects:  85% (51/60)   \rUnpacking objects:  86% (52/60)   \rUnpacking objects:  88% (53/60)   \rUnpacking objects:  90% (54/60)   \rUnpacking objects:  91% (55/60)   \rUnpacking objects:  93% (56/60)   \rUnpacking objects:  95% (57/60)   \rUnpacking objects:  96% (58/60)   \rUnpacking objects:  98% (59/60)   \rUnpacking objects: 100% (60/60)   \rUnpacking objects: 100% (60/60), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "21kBv_MN8oAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e062940a-422a-451b-8ee6-4dfa25d5f57b"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.7.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow) (1.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow) (0.9999999)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow) (40.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V3PjzbRC9Ehm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d710c45-d7a2-4522-8e72-eb7fddf4e637"
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a7JbcquA9fFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffcf0f20-edde-480f-d267-336a906a136e"
      },
      "cell_type": "code",
      "source": [
        "cd ctc_tensorflow_example"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ctc_tensorflow_example\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rp9ZR6-J9jpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3692
        },
        "outputId": "af5ed5d4-bcd2-4739-e8f6-6983870978fb"
      },
      "cell_type": "code",
      "source": [
        "!python ctc_tensorflow_example.py"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "Attempting to download: LDC93S1.wav\n",
            "0%............\n",
            "Download Complete!\n",
            "Found and verified LDC93S1.wav\n",
            "Attempting to download: LDC93S1.txt\n",
            "0%.\n",
            "Download Complete!\n",
            "Found and verified LDC93S1.txt\n",
            "2019-04-13 18:31:27.070922: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "Epoch 1/200, train_cost = 761.788, train_ler = 1.000, val_cost = 294.680, val_ler = 1.000, time = 0.400\n",
            "Epoch 2/200, train_cost = 294.680, train_ler = 1.000, val_cost = 659.610, val_ler = 1.000, time = 0.139\n",
            "Epoch 3/200, train_cost = 659.610, train_ler = 1.000, val_cost = 626.981, val_ler = 1.000, time = 0.140\n",
            "Epoch 4/200, train_cost = 626.981, train_ler = 1.000, val_cost = 301.082, val_ler = 1.000, time = 0.146\n",
            "Epoch 5/200, train_cost = 301.082, train_ler = 0.808, val_cost = 262.033, val_ler = 0.808, time = 0.146\n",
            "Epoch 6/200, train_cost = 262.033, train_ler = 0.962, val_cost = 215.741, val_ler = 0.962, time = 0.142\n",
            "Epoch 7/200, train_cost = 215.741, train_ler = 0.981, val_cost = 225.218, val_ler = 0.981, time = 0.164\n",
            "Epoch 8/200, train_cost = 225.218, train_ler = 0.981, val_cost = 204.907, val_ler = 0.981, time = 0.143\n",
            "Epoch 9/200, train_cost = 204.907, train_ler = 0.981, val_cost = 210.961, val_ler = 0.981, time = 0.153\n",
            "Epoch 10/200, train_cost = 210.961, train_ler = 0.981, val_cost = 178.551, val_ler = 0.981, time = 0.151\n",
            "Epoch 11/200, train_cost = 178.551, train_ler = 0.923, val_cost = 175.907, val_ler = 0.923, time = 0.144\n",
            "Epoch 12/200, train_cost = 175.907, train_ler = 0.904, val_cost = 160.245, val_ler = 0.904, time = 0.141\n",
            "Epoch 13/200, train_cost = 160.245, train_ler = 0.808, val_cost = 157.544, val_ler = 0.808, time = 0.148\n",
            "Epoch 14/200, train_cost = 157.544, train_ler = 0.788, val_cost = 157.408, val_ler = 0.788, time = 0.154\n",
            "Epoch 15/200, train_cost = 157.408, train_ler = 0.885, val_cost = 147.541, val_ler = 0.885, time = 0.147\n",
            "Epoch 16/200, train_cost = 147.541, train_ler = 0.885, val_cost = 148.943, val_ler = 0.885, time = 0.141\n",
            "Epoch 17/200, train_cost = 148.943, train_ler = 0.788, val_cost = 140.677, val_ler = 0.788, time = 0.149\n",
            "Epoch 18/200, train_cost = 140.677, train_ler = 0.712, val_cost = 136.425, val_ler = 0.712, time = 0.142\n",
            "Epoch 19/200, train_cost = 136.425, train_ler = 0.712, val_cost = 131.044, val_ler = 0.712, time = 0.147\n",
            "Epoch 20/200, train_cost = 131.044, train_ler = 0.750, val_cost = 133.282, val_ler = 0.750, time = 0.143\n",
            "Epoch 21/200, train_cost = 133.282, train_ler = 0.673, val_cost = 173.239, val_ler = 0.673, time = 0.156\n",
            "Epoch 22/200, train_cost = 173.239, train_ler = 0.712, val_cost = 142.236, val_ler = 0.712, time = 0.145\n",
            "Epoch 23/200, train_cost = 142.236, train_ler = 0.827, val_cost = 148.631, val_ler = 0.827, time = 0.145\n",
            "Epoch 24/200, train_cost = 148.631, train_ler = 0.865, val_cost = 151.048, val_ler = 0.865, time = 0.143\n",
            "Epoch 25/200, train_cost = 151.048, train_ler = 0.769, val_cost = 135.533, val_ler = 0.769, time = 0.148\n",
            "Epoch 26/200, train_cost = 135.533, train_ler = 0.750, val_cost = 129.516, val_ler = 0.750, time = 0.148\n",
            "Epoch 27/200, train_cost = 129.516, train_ler = 0.712, val_cost = 134.128, val_ler = 0.712, time = 0.150\n",
            "Epoch 28/200, train_cost = 134.128, train_ler = 0.692, val_cost = 126.734, val_ler = 0.692, time = 0.159\n",
            "Epoch 29/200, train_cost = 126.734, train_ler = 0.692, val_cost = 116.924, val_ler = 0.692, time = 0.142\n",
            "Epoch 30/200, train_cost = 116.924, train_ler = 0.692, val_cost = 113.159, val_ler = 0.692, time = 0.150\n",
            "Epoch 31/200, train_cost = 113.159, train_ler = 0.750, val_cost = 114.405, val_ler = 0.750, time = 0.143\n",
            "Epoch 32/200, train_cost = 114.405, train_ler = 0.712, val_cost = 111.977, val_ler = 0.712, time = 0.147\n",
            "Epoch 33/200, train_cost = 111.977, train_ler = 0.712, val_cost = 108.227, val_ler = 0.712, time = 0.141\n",
            "Epoch 34/200, train_cost = 108.227, train_ler = 0.731, val_cost = 107.895, val_ler = 0.731, time = 0.149\n",
            "Epoch 35/200, train_cost = 107.895, train_ler = 0.712, val_cost = 107.222, val_ler = 0.712, time = 0.152\n",
            "Epoch 36/200, train_cost = 107.222, train_ler = 0.692, val_cost = 104.627, val_ler = 0.692, time = 0.151\n",
            "Epoch 37/200, train_cost = 104.627, train_ler = 0.654, val_cost = 100.569, val_ler = 0.654, time = 0.143\n",
            "Epoch 38/200, train_cost = 100.569, train_ler = 0.635, val_cost = 97.458, val_ler = 0.635, time = 0.140\n",
            "Epoch 39/200, train_cost = 97.458, train_ler = 0.615, val_cost = 95.491, val_ler = 0.615, time = 0.148\n",
            "Epoch 40/200, train_cost = 95.491, train_ler = 0.577, val_cost = 93.263, val_ler = 0.577, time = 0.144\n",
            "Epoch 41/200, train_cost = 93.263, train_ler = 0.577, val_cost = 90.999, val_ler = 0.577, time = 0.147\n",
            "Epoch 42/200, train_cost = 90.999, train_ler = 0.558, val_cost = 89.091, val_ler = 0.558, time = 0.150\n",
            "Epoch 43/200, train_cost = 89.091, train_ler = 0.558, val_cost = 87.355, val_ler = 0.558, time = 0.147\n",
            "Epoch 44/200, train_cost = 87.355, train_ler = 0.519, val_cost = 85.105, val_ler = 0.519, time = 0.144\n",
            "Epoch 45/200, train_cost = 85.105, train_ler = 0.519, val_cost = 82.936, val_ler = 0.519, time = 0.147\n",
            "Epoch 46/200, train_cost = 82.936, train_ler = 0.558, val_cost = 80.376, val_ler = 0.558, time = 0.145\n",
            "Epoch 47/200, train_cost = 80.376, train_ler = 0.538, val_cost = 77.440, val_ler = 0.538, time = 0.142\n",
            "Epoch 48/200, train_cost = 77.440, train_ler = 0.481, val_cost = 75.163, val_ler = 0.481, time = 0.147\n",
            "Epoch 49/200, train_cost = 75.163, train_ler = 0.462, val_cost = 73.180, val_ler = 0.462, time = 0.155\n",
            "Epoch 50/200, train_cost = 73.180, train_ler = 0.462, val_cost = 70.934, val_ler = 0.462, time = 0.154\n",
            "Epoch 51/200, train_cost = 70.934, train_ler = 0.481, val_cost = 68.744, val_ler = 0.481, time = 0.146\n",
            "Epoch 52/200, train_cost = 68.744, train_ler = 0.462, val_cost = 66.894, val_ler = 0.462, time = 0.151\n",
            "Epoch 53/200, train_cost = 66.894, train_ler = 0.442, val_cost = 65.005, val_ler = 0.442, time = 0.141\n",
            "Epoch 54/200, train_cost = 65.005, train_ler = 0.423, val_cost = 62.877, val_ler = 0.423, time = 0.149\n",
            "Epoch 55/200, train_cost = 62.877, train_ler = 0.365, val_cost = 60.808, val_ler = 0.365, time = 0.145\n",
            "Epoch 56/200, train_cost = 60.808, train_ler = 0.346, val_cost = 58.933, val_ler = 0.346, time = 0.157\n",
            "Epoch 57/200, train_cost = 58.933, train_ler = 0.346, val_cost = 57.176, val_ler = 0.346, time = 0.146\n",
            "Epoch 58/200, train_cost = 57.176, train_ler = 0.346, val_cost = 55.540, val_ler = 0.346, time = 0.147\n",
            "Epoch 59/200, train_cost = 55.540, train_ler = 0.346, val_cost = 54.006, val_ler = 0.346, time = 0.143\n",
            "Epoch 60/200, train_cost = 54.006, train_ler = 0.308, val_cost = 52.347, val_ler = 0.308, time = 0.147\n",
            "Epoch 61/200, train_cost = 52.347, train_ler = 0.269, val_cost = 50.531, val_ler = 0.269, time = 0.155\n",
            "Epoch 62/200, train_cost = 50.531, train_ler = 0.250, val_cost = 48.760, val_ler = 0.250, time = 0.149\n",
            "Epoch 63/200, train_cost = 48.760, train_ler = 0.250, val_cost = 47.116, val_ler = 0.250, time = 0.163\n",
            "Epoch 64/200, train_cost = 47.116, train_ler = 0.250, val_cost = 45.616, val_ler = 0.250, time = 0.152\n",
            "Epoch 65/200, train_cost = 45.616, train_ler = 0.250, val_cost = 44.263, val_ler = 0.250, time = 0.160\n",
            "Epoch 66/200, train_cost = 44.263, train_ler = 0.231, val_cost = 42.988, val_ler = 0.231, time = 0.148\n",
            "Epoch 67/200, train_cost = 42.988, train_ler = 0.231, val_cost = 41.674, val_ler = 0.231, time = 0.146\n",
            "Epoch 68/200, train_cost = 41.674, train_ler = 0.231, val_cost = 40.310, val_ler = 0.231, time = 0.144\n",
            "Epoch 69/200, train_cost = 40.310, train_ler = 0.212, val_cost = 38.993, val_ler = 0.212, time = 0.148\n",
            "Epoch 70/200, train_cost = 38.993, train_ler = 0.192, val_cost = 37.754, val_ler = 0.192, time = 0.159\n",
            "Epoch 71/200, train_cost = 37.754, train_ler = 0.192, val_cost = 36.563, val_ler = 0.192, time = 0.144\n",
            "Epoch 72/200, train_cost = 36.563, train_ler = 0.192, val_cost = 35.425, val_ler = 0.192, time = 0.144\n",
            "Epoch 73/200, train_cost = 35.425, train_ler = 0.173, val_cost = 34.340, val_ler = 0.173, time = 0.149\n",
            "Epoch 74/200, train_cost = 34.340, train_ler = 0.135, val_cost = 33.286, val_ler = 0.135, time = 0.148\n",
            "Epoch 75/200, train_cost = 33.286, train_ler = 0.135, val_cost = 32.256, val_ler = 0.135, time = 0.144\n",
            "Epoch 76/200, train_cost = 32.256, train_ler = 0.135, val_cost = 31.257, val_ler = 0.135, time = 0.151\n",
            "Epoch 77/200, train_cost = 31.257, train_ler = 0.135, val_cost = 30.305, val_ler = 0.135, time = 0.160\n",
            "Epoch 78/200, train_cost = 30.305, train_ler = 0.135, val_cost = 29.413, val_ler = 0.135, time = 0.145\n",
            "Epoch 79/200, train_cost = 29.413, train_ler = 0.135, val_cost = 28.567, val_ler = 0.135, time = 0.147\n",
            "Epoch 80/200, train_cost = 28.567, train_ler = 0.135, val_cost = 27.750, val_ler = 0.135, time = 0.147\n",
            "Epoch 81/200, train_cost = 27.750, train_ler = 0.135, val_cost = 26.957, val_ler = 0.135, time = 0.147\n",
            "Epoch 82/200, train_cost = 26.957, train_ler = 0.135, val_cost = 26.190, val_ler = 0.135, time = 0.144\n",
            "Epoch 83/200, train_cost = 26.190, train_ler = 0.135, val_cost = 25.459, val_ler = 0.135, time = 0.160\n",
            "Epoch 84/200, train_cost = 25.459, train_ler = 0.135, val_cost = 24.777, val_ler = 0.135, time = 0.148\n",
            "Epoch 85/200, train_cost = 24.777, train_ler = 0.135, val_cost = 24.142, val_ler = 0.135, time = 0.145\n",
            "Epoch 86/200, train_cost = 24.142, train_ler = 0.135, val_cost = 23.530, val_ler = 0.135, time = 0.149\n",
            "Epoch 87/200, train_cost = 23.530, train_ler = 0.135, val_cost = 22.930, val_ler = 0.135, time = 0.146\n",
            "Epoch 88/200, train_cost = 22.930, train_ler = 0.135, val_cost = 22.350, val_ler = 0.135, time = 0.149\n",
            "Epoch 89/200, train_cost = 22.350, train_ler = 0.135, val_cost = 21.795, val_ler = 0.135, time = 0.150\n",
            "Epoch 90/200, train_cost = 21.795, train_ler = 0.135, val_cost = 21.265, val_ler = 0.135, time = 0.163\n",
            "Epoch 91/200, train_cost = 21.265, train_ler = 0.135, val_cost = 20.757, val_ler = 0.135, time = 0.149\n",
            "Epoch 92/200, train_cost = 20.757, train_ler = 0.135, val_cost = 20.267, val_ler = 0.135, time = 0.152\n",
            "Epoch 93/200, train_cost = 20.267, train_ler = 0.135, val_cost = 19.788, val_ler = 0.135, time = 0.146\n",
            "Epoch 94/200, train_cost = 19.788, train_ler = 0.135, val_cost = 19.320, val_ler = 0.135, time = 0.149\n",
            "Epoch 95/200, train_cost = 19.320, train_ler = 0.135, val_cost = 18.863, val_ler = 0.135, time = 0.145\n",
            "Epoch 96/200, train_cost = 18.863, train_ler = 0.115, val_cost = 18.416, val_ler = 0.115, time = 0.151\n",
            "Epoch 97/200, train_cost = 18.416, train_ler = 0.115, val_cost = 17.981, val_ler = 0.115, time = 0.154\n",
            "Epoch 98/200, train_cost = 17.981, train_ler = 0.115, val_cost = 17.557, val_ler = 0.115, time = 0.150\n",
            "Epoch 99/200, train_cost = 17.557, train_ler = 0.135, val_cost = 17.143, val_ler = 0.135, time = 0.143\n",
            "Epoch 100/200, train_cost = 17.143, train_ler = 0.135, val_cost = 16.741, val_ler = 0.135, time = 0.150\n",
            "Epoch 101/200, train_cost = 16.741, train_ler = 0.135, val_cost = 16.350, val_ler = 0.135, time = 0.144\n",
            "Epoch 102/200, train_cost = 16.350, train_ler = 0.115, val_cost = 15.965, val_ler = 0.115, time = 0.144\n",
            "Epoch 103/200, train_cost = 15.965, train_ler = 0.115, val_cost = 15.587, val_ler = 0.115, time = 0.148\n",
            "Epoch 104/200, train_cost = 15.587, train_ler = 0.115, val_cost = 15.221, val_ler = 0.115, time = 0.154\n",
            "Epoch 105/200, train_cost = 15.221, train_ler = 0.115, val_cost = 14.865, val_ler = 0.115, time = 0.148\n",
            "Epoch 106/200, train_cost = 14.865, train_ler = 0.115, val_cost = 14.517, val_ler = 0.115, time = 0.142\n",
            "Epoch 107/200, train_cost = 14.517, train_ler = 0.115, val_cost = 14.175, val_ler = 0.115, time = 0.147\n",
            "Epoch 108/200, train_cost = 14.175, train_ler = 0.096, val_cost = 13.843, val_ler = 0.096, time = 0.142\n",
            "Epoch 109/200, train_cost = 13.843, train_ler = 0.058, val_cost = 13.519, val_ler = 0.058, time = 0.147\n",
            "Epoch 110/200, train_cost = 13.519, train_ler = 0.038, val_cost = 13.198, val_ler = 0.038, time = 0.142\n",
            "Epoch 111/200, train_cost = 13.198, train_ler = 0.038, val_cost = 12.882, val_ler = 0.038, time = 0.160\n",
            "Epoch 112/200, train_cost = 12.882, train_ler = 0.038, val_cost = 12.575, val_ler = 0.038, time = 0.143\n",
            "Epoch 113/200, train_cost = 12.575, train_ler = 0.038, val_cost = 12.277, val_ler = 0.038, time = 0.150\n",
            "Epoch 114/200, train_cost = 12.277, train_ler = 0.038, val_cost = 11.986, val_ler = 0.038, time = 0.146\n",
            "Epoch 115/200, train_cost = 11.986, train_ler = 0.038, val_cost = 11.701, val_ler = 0.038, time = 0.143\n",
            "Epoch 116/200, train_cost = 11.701, train_ler = 0.038, val_cost = 11.423, val_ler = 0.038, time = 0.148\n",
            "Epoch 117/200, train_cost = 11.423, train_ler = 0.038, val_cost = 11.153, val_ler = 0.038, time = 0.153\n",
            "Epoch 118/200, train_cost = 11.153, train_ler = 0.038, val_cost = 10.889, val_ler = 0.038, time = 0.156\n",
            "Epoch 119/200, train_cost = 10.889, train_ler = 0.019, val_cost = 10.633, val_ler = 0.019, time = 0.148\n",
            "Epoch 120/200, train_cost = 10.633, train_ler = 0.019, val_cost = 10.387, val_ler = 0.019, time = 0.149\n",
            "Epoch 121/200, train_cost = 10.387, train_ler = 0.019, val_cost = 10.149, val_ler = 0.019, time = 0.142\n",
            "Epoch 122/200, train_cost = 10.149, train_ler = 0.019, val_cost = 9.920, val_ler = 0.019, time = 0.149\n",
            "Epoch 123/200, train_cost = 9.920, train_ler = 0.038, val_cost = 9.698, val_ler = 0.038, time = 0.144\n",
            "Epoch 124/200, train_cost = 9.698, train_ler = 0.019, val_cost = 9.484, val_ler = 0.019, time = 0.150\n",
            "Epoch 125/200, train_cost = 9.484, train_ler = 0.019, val_cost = 9.275, val_ler = 0.019, time = 0.152\n",
            "Epoch 126/200, train_cost = 9.275, train_ler = 0.019, val_cost = 9.072, val_ler = 0.019, time = 0.152\n",
            "Epoch 127/200, train_cost = 9.072, train_ler = 0.019, val_cost = 8.874, val_ler = 0.019, time = 0.151\n",
            "Epoch 128/200, train_cost = 8.874, train_ler = 0.019, val_cost = 8.681, val_ler = 0.019, time = 0.152\n",
            "Epoch 129/200, train_cost = 8.681, train_ler = 0.019, val_cost = 8.492, val_ler = 0.019, time = 0.143\n",
            "Epoch 130/200, train_cost = 8.492, train_ler = 0.019, val_cost = 8.308, val_ler = 0.019, time = 0.148\n",
            "Epoch 131/200, train_cost = 8.308, train_ler = 0.019, val_cost = 8.127, val_ler = 0.019, time = 0.143\n",
            "Epoch 132/200, train_cost = 8.127, train_ler = 0.019, val_cost = 7.950, val_ler = 0.019, time = 0.159\n",
            "Epoch 133/200, train_cost = 7.950, train_ler = 0.019, val_cost = 7.777, val_ler = 0.019, time = 0.156\n",
            "Epoch 134/200, train_cost = 7.777, train_ler = 0.019, val_cost = 7.608, val_ler = 0.019, time = 0.151\n",
            "Epoch 135/200, train_cost = 7.608, train_ler = 0.019, val_cost = 7.442, val_ler = 0.019, time = 0.148\n",
            "Epoch 136/200, train_cost = 7.442, train_ler = 0.019, val_cost = 7.279, val_ler = 0.019, time = 0.146\n",
            "Epoch 137/200, train_cost = 7.279, train_ler = 0.019, val_cost = 7.119, val_ler = 0.019, time = 0.149\n",
            "Epoch 138/200, train_cost = 7.119, train_ler = 0.019, val_cost = 6.963, val_ler = 0.019, time = 0.146\n",
            "Epoch 139/200, train_cost = 6.963, train_ler = 0.019, val_cost = 6.811, val_ler = 0.019, time = 0.161\n",
            "Epoch 140/200, train_cost = 6.811, train_ler = 0.019, val_cost = 6.663, val_ler = 0.019, time = 0.142\n",
            "Epoch 141/200, train_cost = 6.663, train_ler = 0.019, val_cost = 6.518, val_ler = 0.019, time = 0.151\n",
            "Epoch 142/200, train_cost = 6.518, train_ler = 0.019, val_cost = 6.379, val_ler = 0.019, time = 0.145\n",
            "Epoch 143/200, train_cost = 6.379, train_ler = 0.019, val_cost = 6.243, val_ler = 0.019, time = 0.147\n",
            "Epoch 144/200, train_cost = 6.243, train_ler = 0.019, val_cost = 6.111, val_ler = 0.019, time = 0.148\n",
            "Epoch 145/200, train_cost = 6.111, train_ler = 0.019, val_cost = 5.984, val_ler = 0.019, time = 0.153\n",
            "Epoch 146/200, train_cost = 5.984, train_ler = 0.000, val_cost = 5.860, val_ler = 0.000, time = 0.155\n",
            "Epoch 147/200, train_cost = 5.860, train_ler = 0.000, val_cost = 5.740, val_ler = 0.000, time = 0.151\n",
            "Epoch 148/200, train_cost = 5.740, train_ler = 0.000, val_cost = 5.624, val_ler = 0.000, time = 0.142\n",
            "Epoch 149/200, train_cost = 5.624, train_ler = 0.000, val_cost = 5.511, val_ler = 0.000, time = 0.147\n",
            "Epoch 150/200, train_cost = 5.511, train_ler = 0.000, val_cost = 5.400, val_ler = 0.000, time = 0.143\n",
            "Epoch 151/200, train_cost = 5.400, train_ler = 0.000, val_cost = 5.293, val_ler = 0.000, time = 0.144\n",
            "Epoch 152/200, train_cost = 5.293, train_ler = 0.000, val_cost = 5.189, val_ler = 0.000, time = 0.159\n",
            "Epoch 153/200, train_cost = 5.189, train_ler = 0.000, val_cost = 5.088, val_ler = 0.000, time = 0.149\n",
            "Epoch 154/200, train_cost = 5.088, train_ler = 0.000, val_cost = 4.989, val_ler = 0.000, time = 0.150\n",
            "Epoch 155/200, train_cost = 4.989, train_ler = 0.000, val_cost = 4.893, val_ler = 0.000, time = 0.142\n",
            "Epoch 156/200, train_cost = 4.893, train_ler = 0.000, val_cost = 4.800, val_ler = 0.000, time = 0.146\n",
            "Epoch 157/200, train_cost = 4.800, train_ler = 0.000, val_cost = 4.708, val_ler = 0.000, time = 0.145\n",
            "Epoch 158/200, train_cost = 4.708, train_ler = 0.000, val_cost = 4.619, val_ler = 0.000, time = 0.153\n",
            "Epoch 159/200, train_cost = 4.619, train_ler = 0.000, val_cost = 4.533, val_ler = 0.000, time = 0.151\n",
            "Epoch 160/200, train_cost = 4.533, train_ler = 0.000, val_cost = 4.448, val_ler = 0.000, time = 0.151\n",
            "Epoch 161/200, train_cost = 4.448, train_ler = 0.000, val_cost = 4.365, val_ler = 0.000, time = 0.142\n",
            "Epoch 162/200, train_cost = 4.365, train_ler = 0.000, val_cost = 4.285, val_ler = 0.000, time = 0.152\n",
            "Epoch 163/200, train_cost = 4.285, train_ler = 0.000, val_cost = 4.206, val_ler = 0.000, time = 0.146\n",
            "Epoch 164/200, train_cost = 4.206, train_ler = 0.000, val_cost = 4.128, val_ler = 0.000, time = 0.146\n",
            "Epoch 165/200, train_cost = 4.128, train_ler = 0.000, val_cost = 4.053, val_ler = 0.000, time = 0.145\n",
            "Epoch 166/200, train_cost = 4.053, train_ler = 0.000, val_cost = 3.979, val_ler = 0.000, time = 0.162\n",
            "Epoch 167/200, train_cost = 3.979, train_ler = 0.000, val_cost = 3.906, val_ler = 0.000, time = 0.146\n",
            "Epoch 168/200, train_cost = 3.906, train_ler = 0.000, val_cost = 3.835, val_ler = 0.000, time = 0.146\n",
            "Epoch 169/200, train_cost = 3.835, train_ler = 0.000, val_cost = 3.765, val_ler = 0.000, time = 0.146\n",
            "Epoch 170/200, train_cost = 3.765, train_ler = 0.000, val_cost = 3.696, val_ler = 0.000, time = 0.145\n",
            "Epoch 171/200, train_cost = 3.696, train_ler = 0.000, val_cost = 3.628, val_ler = 0.000, time = 0.150\n",
            "Epoch 172/200, train_cost = 3.628, train_ler = 0.000, val_cost = 3.561, val_ler = 0.000, time = 0.152\n",
            "Epoch 173/200, train_cost = 3.561, train_ler = 0.000, val_cost = 3.494, val_ler = 0.000, time = 0.162\n",
            "Epoch 174/200, train_cost = 3.494, train_ler = 0.000, val_cost = 3.429, val_ler = 0.000, time = 0.143\n",
            "Epoch 175/200, train_cost = 3.429, train_ler = 0.000, val_cost = 3.364, val_ler = 0.000, time = 0.148\n",
            "Epoch 176/200, train_cost = 3.364, train_ler = 0.000, val_cost = 3.300, val_ler = 0.000, time = 0.143\n",
            "Epoch 177/200, train_cost = 3.300, train_ler = 0.000, val_cost = 3.237, val_ler = 0.000, time = 0.148\n",
            "Epoch 178/200, train_cost = 3.237, train_ler = 0.000, val_cost = 3.174, val_ler = 0.000, time = 0.144\n",
            "Epoch 179/200, train_cost = 3.174, train_ler = 0.000, val_cost = 3.113, val_ler = 0.000, time = 0.158\n",
            "Epoch 180/200, train_cost = 3.113, train_ler = 0.000, val_cost = 3.052, val_ler = 0.000, time = 0.153\n",
            "Epoch 181/200, train_cost = 3.052, train_ler = 0.000, val_cost = 2.992, val_ler = 0.000, time = 0.148\n",
            "Epoch 182/200, train_cost = 2.992, train_ler = 0.000, val_cost = 2.933, val_ler = 0.000, time = 0.156\n",
            "Epoch 183/200, train_cost = 2.933, train_ler = 0.000, val_cost = 2.876, val_ler = 0.000, time = 0.152\n",
            "Epoch 184/200, train_cost = 2.876, train_ler = 0.000, val_cost = 2.819, val_ler = 0.000, time = 0.147\n",
            "Epoch 185/200, train_cost = 2.819, train_ler = 0.000, val_cost = 2.764, val_ler = 0.000, time = 0.165\n",
            "Epoch 186/200, train_cost = 2.764, train_ler = 0.000, val_cost = 2.710, val_ler = 0.000, time = 0.154\n",
            "Epoch 187/200, train_cost = 2.710, train_ler = 0.000, val_cost = 2.657, val_ler = 0.000, time = 0.163\n",
            "Epoch 188/200, train_cost = 2.657, train_ler = 0.000, val_cost = 2.605, val_ler = 0.000, time = 0.148\n",
            "Epoch 189/200, train_cost = 2.605, train_ler = 0.000, val_cost = 2.555, val_ler = 0.000, time = 0.157\n",
            "Epoch 190/200, train_cost = 2.555, train_ler = 0.000, val_cost = 2.506, val_ler = 0.000, time = 0.146\n",
            "Epoch 191/200, train_cost = 2.506, train_ler = 0.000, val_cost = 2.459, val_ler = 0.000, time = 0.152\n",
            "Epoch 192/200, train_cost = 2.459, train_ler = 0.000, val_cost = 2.412, val_ler = 0.000, time = 0.150\n",
            "Epoch 193/200, train_cost = 2.412, train_ler = 0.000, val_cost = 2.367, val_ler = 0.000, time = 0.160\n",
            "Epoch 194/200, train_cost = 2.367, train_ler = 0.000, val_cost = 2.324, val_ler = 0.000, time = 0.151\n",
            "Epoch 195/200, train_cost = 2.324, train_ler = 0.000, val_cost = 2.281, val_ler = 0.000, time = 0.153\n",
            "Epoch 196/200, train_cost = 2.281, train_ler = 0.000, val_cost = 2.240, val_ler = 0.000, time = 0.147\n",
            "Epoch 197/200, train_cost = 2.240, train_ler = 0.000, val_cost = 2.200, val_ler = 0.000, time = 0.152\n",
            "Epoch 198/200, train_cost = 2.200, train_ler = 0.000, val_cost = 2.162, val_ler = 0.000, time = 0.150\n",
            "Epoch 199/200, train_cost = 2.162, train_ler = 0.000, val_cost = 2.124, val_ler = 0.000, time = 0.150\n",
            "Epoch 200/200, train_cost = 2.124, train_ler = 0.000, val_cost = 2.088, val_ler = 0.000, time = 0.155\n",
            "Original:\n",
            "she had your dark suit in greasy wash water all year\n",
            "Decoded:\n",
            "she had your dark suit in greasy wash water all year\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J5JBPXhY9wtv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python utils.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZrYswcCf97ie",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}